/**
 * ä¸Šä¼ ç¼“å­˜çš„åµŒå…¥å‘é‡åˆ°æ•°æ®åº“ (Bulk Upsert æ–¹æ¡ˆ)
 *
 * æœ€ä½³å®è·µï¼š
 * 1. ä½¿ç”¨ INSERT ... ON CONFLICT DO UPDATE (æ‰¹é‡æ’å…¥/å†²çªæ›´æ–°)
 * 2. æœ€å°åŒ–ç½‘ç»œå¾€è¿”ï¼Œä» 910 æ¬¡è¯·æ±‚å‡å°‘åˆ° 9-10 æ¬¡æ‰¹é‡è¯·æ±‚
 * 3. ä¸éœ€è¦é¢„å…ˆæŸ¥è¯¢ IDï¼Œæ•°æ®åº“è‡ªåŠ¨å¤„ç†æ’å…¥æˆ–æ›´æ–°
 *
 * ä½¿ç”¨æ–¹å¼ï¼š
 * bun run scripts/upload-cached-embeddings.ts
 */

import { db } from '@/lib/db'
import { userEmbeddings } from '@/lib/db/schema'
import { sql } from 'drizzle-orm'
import { readFileSync, existsSync } from 'fs'
import { join } from 'path'

interface CachedEmbedding {
  id: string
  userId: string
  type: 'interest' | 'need' | 'provide' | 'profile'
  sourceText: string
  sourceIndex: number
  embedding: number[]
  cachedAt: string
}

interface OfflineUser {
  id: string
  name: string
  age: number
  gender: string
  city: string
  bio: string
  interests: string[]
  needs: string[]
  provide: string[]
}

interface OfflineCacheData {
  generatedAt: string
  totalUsers: number
  users: OfflineUser[]
  embeddings: CachedEmbedding[]
}

// é…ç½®
const CACHE_FILE_PATH = join(process.cwd(), 'data', 'embeddings-cache.json')
const BATCH_SIZE = 100 // æ¯æ‰¹ 100 æ¡ï¼Œå¹³è¡¡å‚æ•°æ•°é‡å’Œç½‘ç»œå»¶è¿Ÿ

async function main() {
  console.log('='.repeat(80))
  console.log('å¼€å§‹ä¸Šä¼ ç¼“å­˜çš„åµŒå…¥å‘é‡åˆ°æ•°æ®åº“ (Bulk Upsert)')
  console.log('='.repeat(80))

  // æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
  if (!existsSync(CACHE_FILE_PATH)) {
    console.error(`\né”™è¯¯: ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨`)
    console.error(`è·¯å¾„: ${CACHE_FILE_PATH}`)
    console.error(`\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆå‘é‡:`)
    console.error(`  bun run scripts/generate-embeddings-offline.ts`)
    process.exit(1)
  }

  // è¯»å–ç¼“å­˜
  const cacheData: OfflineCacheData = JSON.parse(readFileSync(CACHE_FILE_PATH, 'utf-8'))
  console.log(`\nç¼“å­˜ä¿¡æ¯:`)
  console.log(`  ç”Ÿæˆæ—¶é—´: ${cacheData.generatedAt}`)
  console.log(`  ç”¨æˆ·æ•°é‡: ${cacheData.users.length}`)
  console.log(`  å‘é‡æ•°é‡: ${cacheData.embeddings.length}`)

  if (cacheData.embeddings.length === 0) {
    console.log('\nç¼“å­˜ä¸ºç©ºï¼Œæ— éœ€ä¸Šä¼ ')
    return
  }

  // è¿‡æ»¤æ—§æ ¼å¼å‘é‡ï¼ˆæ²¡æœ‰ type å­—æ®µçš„ï¼‰
  const validEmbeddings = cacheData.embeddings.filter(
    e => e.type && e.sourceIndex !== undefined && e.embedding?.length > 0
  )

  console.log(`\nè¿‡æ»¤æ—§æ ¼å¼å‘é‡:`)
  console.log(`  æ€»å‘é‡æ•°: ${cacheData.embeddings.length}`)
  console.log(`  æœ‰æ•ˆå‘é‡æ•°: ${validEmbeddings.length}`)
  console.log(`  è¿‡æ»¤æ‰: ${cacheData.embeddings.length - validEmbeddings.length}`)

  if (validEmbeddings.length === 0) {
    console.log('\næ²¡æœ‰æœ‰æ•ˆçš„å‘é‡å¯ä¸Šä¼ ')
    return
  }

  // åˆ†æ‰¹ä¸Šä¼ 
  const totalBatches = Math.ceil(validEmbeddings.length / BATCH_SIZE)
  let totalSuccess = 0
  let totalFailed = 0

  console.log(`\nå¼€å§‹æ‰¹é‡ä¸Šä¼  (${totalBatches} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹ ${BATCH_SIZE} æ¡)...`)
  console.log('-'.repeat(80))

  const startTime = Date.now()

  for (let i = 0; i < validEmbeddings.length; i += BATCH_SIZE) {
    const batchNum = Math.floor(i / BATCH_SIZE) + 1
    const chunk = validEmbeddings.slice(i, i + BATCH_SIZE)

    console.log(`\n[æ‰¹æ¬¡ ${batchNum}/${totalBatches}] ä¸Šä¼  ${chunk.length} æ¡å‘é‡...`)

    // æ„é€ ç¬¦åˆ DB ç»“æ„çš„æ•°æ®å¯¹è±¡
    const values = chunk.map(item => ({
      userId: item.userId,
      embeddingType: item.type,
      sourceText: item.sourceText,
      sourceIndex: item.sourceIndex,
      embedding: item.embedding,
      embeddingGenerationStatus: 'completed' as const,
      embeddingGeneratedAt: new Date(item.cachedAt),
      updatedAt: new Date(),
    }))

    // æ­¥éª¤ 1ï¼šå°è¯•æ‰¹é‡ä¸Šä¼ ï¼ˆé‡è¯• 3 æ¬¡ï¼‰
    const MAX_RETRIES = 3
    let batchSuccess = false
    let lastError: Error | null = null

    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
      try {
        await db.insert(userEmbeddings)
          .values(values)
          .onConflictDoUpdate({
            target: [
              userEmbeddings.userId,
              userEmbeddings.embeddingType,
              userEmbeddings.sourceIndex,
            ],
            set: {
              embedding: sql`excluded.embedding`,
              embeddingGenerationStatus: sql`excluded.embedding_generation_status`,
              embeddingGeneratedAt: sql`excluded.embedding_generated_at`,
              updatedAt: new Date(),
            },
          })

        batchSuccess = true
        totalSuccess += chunk.length
        console.log(`  âœ“ æ‰¹æ¬¡æˆåŠŸ (${chunk.length} æ¡)`)

        // æ˜¾ç¤ºè¿›åº¦
        const progress = Math.round(((i + chunk.length) / validEmbeddings.length) * 100)
        console.log(`  è¿›åº¦: ${progress}%`)
        break
      } catch (error) {
        lastError = error as Error
        if (attempt < MAX_RETRIES) {
          console.log(`  âš ï¸  æ‰¹æ¬¡å¤±è´¥ï¼Œç¬¬ ${attempt} æ¬¡é‡è¯•ä¸­...`)
          await delay(1000)
        } else {
          console.log(`  âœ— æ‰¹æ¬¡é‡è¯• ${MAX_RETRIES} æ¬¡åä»å¤±è´¥`)
        }
      }
    }

    // æ­¥éª¤ 2ï¼šé‡è¯•å¤±è´¥ï¼Œé™çº§ä¸ºé€æ¡ä¸Šä¼ 
    if (!batchSuccess) {
      const errorMsg = lastError?.message || String(lastError)
      console.error(`  é”™è¯¯:`, errorMsg.slice(0, 200) + (errorMsg.length > 200 ? '...' : ''))
      console.log(`  ğŸ”„ é™çº§ä¸ºé€æ¡ä¸Šä¼ ...`)

      let batchSuccessCount = 0
      let batchFailedCount = 0

      for (const item of chunk) {
        try {
          const value = {
            userId: item.userId,
            embeddingType: item.type,
            sourceText: item.sourceText,
            sourceIndex: item.sourceIndex,
            embedding: item.embedding,
            embeddingGenerationStatus: 'completed' as const,
            embeddingGeneratedAt: new Date(item.cachedAt),
            updatedAt: new Date(),
          }

          await db.insert(userEmbeddings)
            .values(value)
            .onConflictDoUpdate({
              target: [
                userEmbeddings.userId,
                userEmbeddings.embeddingType,
                userEmbeddings.sourceIndex,
              ],
              set: {
                embedding: sql`excluded.embedding`,
                embeddingGenerationStatus: sql`excluded.embedding_generation_status`,
                embeddingGeneratedAt: sql`excluded.embedding_generated_at`,
                updatedAt: new Date(),
              },
            })

          batchSuccessCount++
          totalSuccess++
          process.stdout.write('.')
        } catch (singleError) {
          batchFailedCount++
          totalFailed++
          process.stdout.write('x')
        }
      }

      console.log()
      console.log(`  é€æ¡ä¸Šä¼ å®Œæˆ: æˆåŠŸ ${batchSuccessCount} æ¡, å¤±è´¥ ${batchFailedCount} æ¡`)

      // æ˜¾ç¤ºè¿›åº¦
      const progress = Math.round(((i + chunk.length) / validEmbeddings.length) * 100)
      console.log(`  è¿›åº¦: ${progress}%`)
    }
  }

  const elapsed = ((Date.now() - startTime) / 1000).toFixed(2)

  // æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
  console.log('\n' + '='.repeat(80))
  console.log('ä¸Šä¼ å®Œæˆï¼')
  console.log('='.repeat(80))
  console.log(`ç¼“å­˜æ€»å‘é‡æ•°: ${cacheData.embeddings.length}`)
  console.log(`æœ‰æ•ˆå‘é‡æ•°: ${validEmbeddings.length}`)
  console.log(`æˆåŠŸä¸Šä¼ : ${totalSuccess}`)
  console.log(`å¤±è´¥æ•°é‡: ${totalFailed}`)
  console.log(`è€—æ—¶: ${elapsed} ç§’`)

  if (totalFailed === 0) {
    console.log('\nâœ… æ‰€æœ‰å‘é‡ä¸Šä¼ æˆåŠŸï¼')
    console.log('\nä¸‹ä¸€æ­¥: è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æ•°æ®')
    console.log(`  bun run scripts/verify-all-data.ts`)
  } else {
    console.log(`\nâš ï¸  æœ‰ ${totalFailed} ä¸ªå‘é‡ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯å¹¶é‡è¯•`)
  }

  console.log('='.repeat(80))
}

main()
  .then(() => {
    console.log('\nè„šæœ¬æ‰§è¡Œå®Œæˆ')
    process.exit(0)
  })
  .catch((error) => {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error('è„šæœ¬æ‰§è¡Œå¤±è´¥:', errorMsg.slice(0, 500))
    process.exit(1)
  })
